{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c5f6a0",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION\n",
    "\n",
    "From the benchmark notebook and data set provided it is clear that the data used lacks depth in terms of driver columns for the target variables.\n",
    "\n",
    "Also taking to account that using Microsoft planetary data takes more time I will instead use data from Google Earth Engine.\n",
    "\n",
    "The data extracted will include:\n",
    "- raw bands wich will help us calulate Turbidity and other driver features (green, blue, red, NIR, SWIR1, SWIR2)\n",
    "- Environmental and Terrain factors (precipitation, temperature, pet, evlevation, slope, soil composition etc.)\n",
    "- Surrounding and Landcover type features (water occurence, population, land cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b819832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Library Importation\n",
    "import ee\n",
    "import geemap\n",
    "import google.auth\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ed3963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authentication and initialization\n",
    "ee.Initialize(project = 'cleanwatai-466814')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf27cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Extraction...\n",
      "  Training started — monitoring...\n",
      "  ... Training status: READY\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ... Training status: RUNNING\n",
      "  ✅ Training complete!\n",
      "\n",
      "==============================\n",
      "Starting Validation Extraction...\n",
      "  Validation started — monitoring...\n",
      "  ... Validation status: READY\n",
      "  ... Validation status: RUNNING\n",
      "  ... Validation status: RUNNING\n",
      "  ✅ Validation complete!\n",
      "\n",
      "Done! Check your Google Drive folder: EE_Exports\n"
     ]
    }
   ],
   "source": [
    "# Library Importation\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "ee.Initialize(project='cleanwatai-466814')\n",
    "\n",
    "\n",
    "def run_clean_sweep(csv_path, output_name, export_folder='EE_Exports'):\n",
    "\n",
    "    # Configuration constants\n",
    "    BUFFER_SIZE_SMALL  = 30\n",
    "    BUFFER_SIZE_LARGE  = 3000\n",
    "    MISSING_VALUE      = -9999\n",
    "    CHIRPS_RESOLUTION  = 5566\n",
    "    ERA5_RESOLUTION    = 11132\n",
    "    SOIL_RESOLUTION    = 250\n",
    "\n",
    "    # Load & clean CSV — only keep columns needed for extraction\n",
    "    # (other columns like NDMI, nir, green etc. may contain NaN which\n",
    "    #  breaks geemap.pandas_to_ee serialization)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    KEEP_COLS = ['Index', 'Latitude', 'Longitude', 'Sample Date']\n",
    "    df = df[KEEP_COLS]\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    assert not df.isnull().values.any(), \"NaN still present after cleaning!\"\n",
    "\n",
    "    points = geemap.pandas_to_ee(df, latitude='Latitude', longitude='Longitude')\n",
    "\n",
    "    bounds     = ee.Geometry.Rectangle([16.0, -35.0, 33.0, -22.0])\n",
    "    sat_window = 30  # Keep tight window — temporal accuracy matters for water quality\n",
    "\n",
    "    # Satellite collections\n",
    "    def mask_landsat(img):\n",
    "        qa   = img.select('QA_PIXEL')\n",
    "        mask = qa.bitwiseAnd(1 << 3).eq(0).And(qa.bitwiseAnd(1 << 4).eq(0))\n",
    "        return img.select(['SR_B.*']).updateMask(mask).multiply(0.0000275).copyProperties(img, ['system:time_start'])\n",
    "\n",
    "    l7 = (ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\")\n",
    "          .filterBounds(bounds).map(mask_landsat)\n",
    "          .select(['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5'],\n",
    "                  ['blue','green','red','nir','swir1']))\n",
    "    l8 = (ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "          .filterBounds(bounds).map(mask_landsat)\n",
    "          .select(['SR_B2','SR_B3','SR_B4','SR_B5','SR_B6'],\n",
    "                  ['blue','green','red','nir','swir1']))\n",
    "    landsat_col = l7.merge(l8)\n",
    "\n",
    "    modis_col = (ee.ImageCollection(\"MODIS/061/MOD09GA\")\n",
    "                 .filterBounds(bounds)\n",
    "                 .select(['sur_refl_b03','sur_refl_b04','sur_refl_b01','sur_refl_b02','sur_refl_b06'],\n",
    "                         ['blue','green','red','nir','swir1'])\n",
    "                 .map(lambda img: img.multiply(0.0001).copyProperties(img, ['system:time_start'])))\n",
    "\n",
    "    chirps    = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "    era5      = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\").select(['temperature_2m','dewpoint_temperature_2m'])\n",
    "    srtm      = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "    jrc       = ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\").select('occurrence')\n",
    "    soil_ph   = ee.Image(\"OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02\").select('b0')\n",
    "    soil_clay = ee.Image(\"OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02\").select('b0')\n",
    "    soil_sand = ee.Image(\"OpenLandMap/SOL/SOL_SAND-WFRACTION_USDA-3A1A1A_M/v02\").select('b0')\n",
    "    ghsl      = ee.ImageCollection(\"JRC/GHSL/P2023A/GHS_POP\")\n",
    "\n",
    "    def extract_features(feature):\n",
    "\n",
    "        date_str    = ee.String(feature.get('Sample Date'))\n",
    "        clean_date  = date_str.replace('/', '-', 'g').replace('\\\\.', '-', 'g')\n",
    "        is_iso      = clean_date.slice(0, 4).match('^[0-9]+$')\n",
    "        date_format = ee.Algorithms.If(is_iso, 'yyyy-MM-dd', 'd-M-y')\n",
    "        sample_date = ee.Date.parse(date_format, clean_date)\n",
    "        geom        = feature.geometry()\n",
    "\n",
    "        # ── Precipitation ────────────────────────────────────────────────────\n",
    "        r0 = chirps.filterDate(sample_date, sample_date.advance(1, 'day')).first()\n",
    "        r1 = chirps.filterDate(sample_date.advance(-1, 'day'), sample_date).first()\n",
    "        r3 = chirps.filterDate(sample_date.advance(-3, 'day'), sample_date.advance(1, 'day')).sum()\n",
    "\n",
    "        # BUG FIX 1: get_precip was using ee.Algorithms.If(value, ...) which\n",
    "        # treats 0.0 (a valid dry-day reading) as falsy → returned -9999.\n",
    "        # Fix: check IsEqual(value, None) explicitly instead of truthiness.\n",
    "        def get_precip(img, geom):\n",
    "            reduced = img.reduceRegion(ee.Reducer.first(), geom, CHIRPS_RESOLUTION)\n",
    "            value   = reduced.get('precipitation')\n",
    "            return ee.Number(ee.Algorithms.If(\n",
    "                ee.Algorithms.IsEqual(value, None),  # Only -9999 if truly absent\n",
    "                MISSING_VALUE,\n",
    "                value\n",
    "            ))\n",
    "\n",
    "        # ── Spectral ─────────────────────────────────────────────────────────\n",
    "        def get_nearest(col):\n",
    "            filt = col.filterDate(\n",
    "                sample_date.advance(-sat_window, 'day'),\n",
    "                sample_date.advance(sat_window, 'day')\n",
    "            ).filterBounds(geom)\n",
    "            nearest = ee.Image(filt.map(lambda img: img.set(\n",
    "                'dist', img.date().difference(sample_date, 'day').abs()\n",
    "            )).sort('dist').first())\n",
    "            return ee.Image(ee.Algorithms.If(\n",
    "                filt.size().gt(0), nearest, ee.Image(0).updateMask(ee.Image(0))\n",
    "            ))\n",
    "\n",
    "        l_img = get_nearest(landsat_col)\n",
    "        m_img = get_nearest(modis_col)\n",
    "        has_l = l_img.bandNames().size().gt(0)\n",
    "        has_m = m_img.bandNames().size().gt(0)\n",
    "\n",
    "        fallback_img = (ee.Image.constant(-9999).rename('blue')\n",
    "                        .addBands(ee.Image.constant(-9999).rename('green'))\n",
    "                        .addBands(ee.Image.constant(-9999).rename('red'))\n",
    "                        .addBands(ee.Image.constant(-9999).rename('nir'))\n",
    "                        .addBands(ee.Image.constant(-9999).rename('swir1')))\n",
    "\n",
    "        final_spec = ee.Image(ee.Algorithms.If(has_l, l_img, ee.Algorithms.If(has_m, m_img, fallback_img)))\n",
    "        final_spec = final_spec.unmask(-9999)\n",
    "        final_spec = final_spec.where(final_spec.neq(final_spec).Or(final_spec.abs().gt(1e10)), -9999)\n",
    "\n",
    "        # FIX: Use IsEqual(dist, None) — dist=0 means same-day image, which is valid\n",
    "        days_offset = ee.Number(ee.Algorithms.If(\n",
    "            has_l,\n",
    "            ee.Algorithms.If(\n",
    "                ee.Algorithms.IsEqual(l_img.get('dist'), None),\n",
    "                MISSING_VALUE,\n",
    "                ee.Number(l_img.get('dist')).abs()\n",
    "            ),\n",
    "            ee.Algorithms.If(\n",
    "                has_m,\n",
    "                ee.Algorithms.If(\n",
    "                    ee.Algorithms.IsEqual(m_img.get('dist'), None),\n",
    "                    MISSING_VALUE,\n",
    "                    ee.Number(m_img.get('dist')).abs()\n",
    "                ),\n",
    "                MISSING_VALUE\n",
    "            )\n",
    "        ))\n",
    "        source = ee.Algorithms.If(has_l, 'Landsat', ee.Algorithms.If(has_m, 'MODIS', 'None'))\n",
    "\n",
    "        s_fallback = ee.Dictionary({'blue': MISSING_VALUE, 'green': MISSING_VALUE, 'red': MISSING_VALUE,\n",
    "                                    'nir': MISSING_VALUE, 'swir1': MISSING_VALUE})\n",
    "        raw_s_vals = ee.Dictionary(ee.Algorithms.If(\n",
    "            final_spec.bandNames().size().gt(0),\n",
    "            # Buffer=90m samples more pixels, reducing chance of all-masked empty result\n",
    "            final_spec.reduceRegion(reducer=ee.Reducer.mean(), geometry=geom.buffer(90),\n",
    "                                    scale=BUFFER_SIZE_SMALL, maxPixels=1e6),\n",
    "            s_fallback\n",
    "        ))\n",
    "        # BUG FIX 2: combine() keeps the CALLING dict's values on key conflicts.\n",
    "        # Old: s_fallback.combine(raw_s_vals) → fallback wins, real data lost!\n",
    "        # Fix: raw_s_vals.combine(s_fallback) → real data wins, fallback only\n",
    "        #      fills keys that are genuinely absent from the real result.\n",
    "        s_vals = raw_s_vals.combine(s_fallback)\n",
    "\n",
    "        # ── Weather ───────────────────────────────────────────────────────────\n",
    "        weather    = era5.filterDate(sample_date, sample_date.advance(1, 'day')).first()\n",
    "        w_fallback = ee.Dictionary({'temperature_2m': MISSING_VALUE, 'dewpoint_temperature_2m': MISSING_VALUE})\n",
    "        raw_w_vals = ee.Dictionary(ee.Algorithms.If(\n",
    "            weather,\n",
    "            weather.reduceRegion(ee.Reducer.first(), geom, ERA5_RESOLUTION, bestEffort=True),\n",
    "            w_fallback\n",
    "        ))\n",
    "        # Same fix: real data takes priority over fallback\n",
    "        w_vals = raw_w_vals.combine(w_fallback)\n",
    "\n",
    "        # BUG FIX 3: get_safe_value was using ee.Algorithms.If(value, ...)\n",
    "        # which treats 0.0 as falsy — any zero measurement returned -9999.\n",
    "        # Fix: explicitly check IsEqual(value, None) for the null test.\n",
    "        def get_safe_value(dict_obj, key, default=MISSING_VALUE):\n",
    "            value = ee.Dictionary(dict_obj).get(key)\n",
    "            return ee.Number(ee.Algorithms.If(\n",
    "                ee.Algorithms.IsEqual(value, None),   # Truly missing?\n",
    "                default,\n",
    "                value                                  # Return as-is (0 is valid!)\n",
    "            ))\n",
    "\n",
    "        # ── Temperature & RH ─────────────────────────────────────────────────\n",
    "        t_raw  = get_safe_value(w_vals, 'temperature_2m')\n",
    "        t      = ee.Number(ee.Algorithms.If(t_raw.neq(MISSING_VALUE), t_raw.subtract(273.15), MISSING_VALUE))\n",
    "\n",
    "        td_raw = get_safe_value(w_vals, 'dewpoint_temperature_2m')\n",
    "        td     = ee.Number(ee.Algorithms.If(td_raw.neq(MISSING_VALUE), td_raw.subtract(273.15), MISSING_VALUE))\n",
    "\n",
    "        # ERA5 always has data globally — RH should virtually never be -9999\n",
    "        rh = ee.Number(ee.Algorithms.If(\n",
    "            t.neq(MISSING_VALUE).And(td.neq(MISSING_VALUE)),\n",
    "            ee.Number(100).multiply(\n",
    "                td.multiply(17.625).divide(td.add(243.04)).exp()\n",
    "            ).divide(\n",
    "                t.multiply(17.625).divide(t.add(243.04)).exp()\n",
    "            ),\n",
    "            MISSING_VALUE\n",
    "        ))\n",
    "\n",
    "        # ── Topography ───────────────────────────────────────────────────────\n",
    "        topo_fallback = ee.Dictionary({'elevation': MISSING_VALUE, 'slope': MISSING_VALUE})\n",
    "        topo = (srtm.addBands(ee.Terrain.slope(srtm))\n",
    "                    .reduceRegion(ee.Reducer.first(), geom, BUFFER_SIZE_SMALL, bestEffort=True)\n",
    "                    .combine(topo_fallback))  # real data wins\n",
    "\n",
    "        # ── Population ───────────────────────────────────────────────────────\n",
    "        # GHSL only has data for: 1975, 1990, 2000, 2015, 2020, 2025, 2030\n",
    "        # For 2011-2014, use closest year (2015)\n",
    "        sample_year = sample_date.get('year')\n",
    "        pop_year = ee.Number(ee.Algorithms.If(\n",
    "            sample_year.lt(2008), 2000,  # Before 2008 → use 2000\n",
    "            ee.Algorithms.If(\n",
    "                sample_year.lt(2018), 2015,  # 2008-2017 → use 2015\n",
    "                2020  # 2018+ → use 2020\n",
    "            )\n",
    "        ))\n",
    "        pop = ghsl.filter(ee.Filter.calendarRange(pop_year, pop_year, 'year')).first()\n",
    "\n",
    "        return feature.set({\n",
    "            # Precipitation — 0 is a valid value, should never be -9999\n",
    "            'precip_0d':        get_precip(r0, geom),\n",
    "            'precip_1d':        get_precip(r1, geom),\n",
    "            'precip_3d_sum':    get_precip(r3, geom),\n",
    "\n",
    "            # Spectral bands\n",
    "            'band_blue':        get_safe_value(s_vals, 'blue'),\n",
    "            'band_green':       get_safe_value(s_vals, 'green'),\n",
    "            'band_red':         get_safe_value(s_vals, 'red'),\n",
    "            'band_nir':         get_safe_value(s_vals, 'nir'),\n",
    "            'band_swir1':       get_safe_value(s_vals, 'swir1'),\n",
    "            'days_offset':      days_offset,\n",
    "\n",
    "            # Weather — ERA5 is global, humidity should virtually never be -9999\n",
    "            'temp_c':           t,\n",
    "            'humidity':         rh,\n",
    "\n",
    "            # Soil\n",
    "            'soil_ph':          get_safe_value(soil_ph.reduceRegion(ee.Reducer.first(), geom, SOIL_RESOLUTION, bestEffort=True), 'b0'),\n",
    "            'soil_clay_perc':   get_safe_value(soil_clay.reduceRegion(ee.Reducer.first(), geom, SOIL_RESOLUTION, bestEffort=True), 'b0'),\n",
    "            'soil_sand_perc':   get_safe_value(soil_sand.reduceRegion(ee.Reducer.first(), geom, SOIL_RESOLUTION, bestEffort=True), 'b0'),\n",
    "\n",
    "            # Topography & water\n",
    "            'elevation':        get_safe_value(topo, 'elevation'),\n",
    "            'slope':            get_safe_value(topo, 'slope'),\n",
    "            'water_occurrence': get_safe_value(\n",
    "                jrc.reduceRegion(ee.Reducer.first(), geom, BUFFER_SIZE_SMALL, bestEffort=True), 'occurrence'\n",
    "            ),\n",
    "\n",
    "            # Population — 0 is valid (uninhabited area)\n",
    "            # FIX: use IsEqual(pop, None) instead of If(pop, ...) so that\n",
    "            # a pop image that exists but returns 0 is not treated as missing\n",
    "            'pop_density_3km':  ee.Number(ee.Algorithms.If(\n",
    "                ee.Algorithms.IsEqual(pop, None),\n",
    "                MISSING_VALUE,\n",
    "                get_safe_value(\n",
    "                    pop.reduceRegion(ee.Reducer.sum(), geom.buffer(BUFFER_SIZE_LARGE), 100),\n",
    "                    'population_count'\n",
    "                )\n",
    "            )),\n",
    "\n",
    "            'data_source': source\n",
    "        })\n",
    "\n",
    "    enriched_points = points.map(extract_features)\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=enriched_points,\n",
    "        description=output_name,\n",
    "        folder=export_folder,\n",
    "        fileNamePrefix=output_name,\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "\n",
    "def wait_for_task(task, label='Task'):\n",
    "    print(f'  {label} started — monitoring...')\n",
    "    while True:\n",
    "        status = task.status()\n",
    "        state  = status['state']\n",
    "        if state == 'COMPLETED':\n",
    "            print(f'  ✅ {label} complete!')\n",
    "            return True\n",
    "        elif state == 'FAILED':\n",
    "            print(f'  ❌ {label} FAILED: {status.get(\"error_message\", \"unknown error\")}')\n",
    "            return False\n",
    "        elif state in ('CANCEL_REQUESTED', 'CANCELLED'):\n",
    "            print(f'  ⚠️  {label} was cancelled.')\n",
    "            return False\n",
    "        else:\n",
    "            print(f'  ... {label} status: {state}')\n",
    "            time.sleep(30)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    EXPORT_FOLDER = 'EE_Exports'\n",
    "\n",
    "    print('Starting Training Extraction...')\n",
    "    train_task = run_clean_sweep('Training_Dataset.csv', 'Training_Master', EXPORT_FOLDER)\n",
    "    wait_for_task(train_task, 'Training')\n",
    "\n",
    "    print('\\n' + '=' * 30)\n",
    "    print('Starting Validation Extraction...')\n",
    "    val_task = run_clean_sweep('Validation_Dataset.csv', 'Validation_Master', EXPORT_FOLDER)\n",
    "    wait_for_task(val_task, 'Validation')\n",
    "\n",
    "    print('\\nDone! Check your Google Drive folder:', EXPORT_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ey_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
